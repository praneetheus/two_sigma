{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import cv2\n",
    "import nltk\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import sys\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StackingClassifier' from 'sklearn.ensemble' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-59f32c3e97d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStackingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'StackingClassifier' from 'sklearn.ensemble' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mile3_df_v2 = pd.read_json(r'C:\\Users\\Giovanni PC\\cmpt459\\data\\ml3\\final_train_df_m3_v2.json')\n",
    "mile3_test_df_v2 = pd.read_json(r'C:\\Users\\Giovanni PC\\cmpt459\\data\\ml3\\final_test_df_m3_v2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mile3_df_v2[\"pos\"] = mile3_df_v2.longitude.round(3).astype(str) + '' + mile3_df_v2.latitude.round(3).astype(str)\n",
    "mile3_test_df_v2[\"pos\"] = mile3_test_df_v2.longitude.round(3).astype(str) + '' + mile3_test_df_v2.latitude.round(3).astype(str)\n",
    "\n",
    "vals = mile3_df_v2['pos'].value_counts()\n",
    "dvals = vals.to_dict()\n",
    "mile3_df_v2[\"density\"] = mile3_df_v2['pos'].apply(lambda x: dvals.get(x, vals.min()))\n",
    "mile3_test_df_v2[\"density\"] = mile3_test_df_v2['pos'].apply(lambda x: dvals.get(x, vals.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created</th>\n",
       "      <th>month_4</th>\n",
       "      <th>manager_skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32941</th>\n",
       "      <td>2016-04-23 01:41:45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.396710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32942</th>\n",
       "      <td>2016-04-12 04:25:33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32943</th>\n",
       "      <td>2016-04-02 05:46:07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32944</th>\n",
       "      <td>2016-04-06 08:10:34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.396710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32945</th>\n",
       "      <td>2016-04-23 02:53:54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48324</th>\n",
       "      <td>2016-04-19 03:31:53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.396710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48325</th>\n",
       "      <td>2016-04-20 02:27:19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.396710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48326</th>\n",
       "      <td>2016-04-02 03:03:42</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48327</th>\n",
       "      <td>2016-04-06 18:15:06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48328</th>\n",
       "      <td>2016-04-22 02:55:58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.127451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15388 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   created  month_4  manager_skill\n",
       "32941  2016-04-23 01:41:45        1       0.396710\n",
       "32942  2016-04-12 04:25:33        1       0.820513\n",
       "32943  2016-04-02 05:46:07        1       0.413793\n",
       "32944  2016-04-06 08:10:34        1       0.396710\n",
       "32945  2016-04-23 02:53:54        1       0.885813\n",
       "...                    ...      ...            ...\n",
       "48324  2016-04-19 03:31:53        1       0.396710\n",
       "48325  2016-04-20 02:27:19        1       0.396710\n",
       "48326  2016-04-02 03:03:42        1       0.504673\n",
       "48327  2016-04-06 18:15:06        1       0.424242\n",
       "48328  2016-04-22 02:55:58        1       1.127451\n",
       "\n",
       "[15388 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mile3_df_v2[[\"created\", \"month_4\", \"manager_skill\"]].query('month_4 > 0')\n",
    "# mile3_df_v2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_selected_feats = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\", \"pet_policy\", \"listing_type\", \n",
    "                     \"unit_features\", \"building_features\", \"apartment\", \"appliance\", \"bathroom\", \"bedroom\",\n",
    "                     \"building\", \"contact\", \"floor\", \"high\", \"kitchen\", \"room\", \"num_photos\", \n",
    "                     \"description_len\", \"mall_distance\", \"dt_distance\", \"managerID_count\", \"buildingID_count\", \n",
    "                    \"weekends\", \"month_4\", \"month_5\", \"created_nights\",\"created_morning\", \"created_afternoon\", \n",
    "                     \"manager_skill\", \"building_interest\", \"density\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mile3_df_v2[v2_selected_feats]\n",
    "y = mile3_df_v2[\"interest_level\"]\n",
    "X_data = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#CV for stacking\n",
    "\n",
    "scores = []\n",
    "train_scores = []\n",
    "train_LogLoss = []\n",
    "test_LogLoss = []\n",
    "num_trees_arr = [100, 150, 200, 250, 300]\n",
    "c_arr = [100, 10, 1, .1, .01]\n",
    "max_feat_arr = [30, 20, 12, 6, 4]\n",
    "min_leaf_nod_arr = [5, 10, 20, 35, 50]\n",
    "deg_arr = [5, 4, 4, 3, 3]\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "i=0\n",
    "for train_index, test_index in cv.split(X):\n",
    "    estimators = [('rf', RandomForestClassifier(n_estimators=num_trees_arr[i], max_features=max_feat_arr[i], random_state=42,\n",
    "                  min_samples_leaf = min_leaf_nod_arr[i])),\n",
    "             ('svr', make_pipeline(StandardScaler(),\n",
    "                                 SVC(C=c_arr[i], kernel = 'sigmoid', degree = deg_arr[i], max_iter=300, gamma='auto', probability=True)))] \n",
    "#                                LinearSVC(random_state=42)))]\n",
    "    clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(C=c_arr[i]))\n",
    "    X_train, X_test, y_train, y_test = X_data[train_index], X_data[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))\n",
    "    train_scores.append(clf.score(X_train, y_train))\n",
    "    y_test_pred = clf.predict_proba(X_test)\n",
    "    test_LogLoss.append(log_loss(y_test, y_test_pred))\n",
    "    y_train_pred = clf.predict_proba(X_train)\n",
    "    train_LogLoss.append(log_loss(y_train, y_train_pred))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-379f75b9524c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_LogLoss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_LogLoss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(train_scores)\n",
    "print(train_LogLoss)\n",
    "print(test_LogLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=None,\n",
       "                   estimators=[('rf',\n",
       "                                RandomForestClassifier(bootstrap=True,\n",
       "                                                       ccp_alpha=0.0,\n",
       "                                                       class_weight=None,\n",
       "                                                       criterion='gini',\n",
       "                                                       max_depth=None,\n",
       "                                                       max_features='auto',\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       max_samples=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100,\n",
       "                                                       n_jobs=None...\n",
       "                                                     shrinking=True, tol=0.001,\n",
       "                                                     verbose=False))],\n",
       "                                         verbose=False))],\n",
       "                   final_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                      dual=False,\n",
       "                                                      fit_intercept=True,\n",
       "                                                      intercept_scaling=1,\n",
       "                                                      l1_ratio=None,\n",
       "                                                      max_iter=100,\n",
       "                                                      multi_class='auto',\n",
       "                                                      n_jobs=None, penalty='l2',\n",
       "                                                      random_state=None,\n",
       "                                                      solver='lbfgs',\n",
       "                                                      tol=0.0001, verbose=0,\n",
       "                                                      warm_start=False),\n",
       "                   n_jobs=None, passthrough=False, stack_method='auto',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74659, 45)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_json(r'C:\\Users\\HP\\Documents\\cmpt 459 Kaggle\\two_sigma\\final_test_df_m3.json')\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kaggle = df_test[v1_selected_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kaggle = clf.predict_proba(X_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2idx = {label: i for i, label in enumerate(clf.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'high': 0, 'low': 1, 'medium': 2}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = df_test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_kaggle[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission_v1_1.0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
